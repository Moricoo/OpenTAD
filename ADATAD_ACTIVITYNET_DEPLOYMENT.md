# AdaTAD ActivityNet é¢„è®­ç»ƒæ¨¡å‹éƒ¨ç½²æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨ä½¿ç”¨AdaTADä½œè€…åœ¨ActivityNet-1.3æ•°æ®é›†ä¸Šè®­ç»ƒçš„**å®˜æ–¹é¢„è®­ç»ƒæƒé‡**ï¼Œéƒ¨ç½²è§†é¢‘æ—¶åºåŠ¨ä½œæ£€æµ‹æœåŠ¡ã€‚

---

## ğŸ“¦ é¢„è®­ç»ƒæƒé‡ä¸‹è½½é“¾æ¥

### æ¨èæ¨¡å‹ï¼ˆæŒ‰æ€§èƒ½æ’åºï¼‰

#### 1. VideoMAEv2-g + InternVideo2ï¼ˆæœ€ä½³æ€§èƒ½ï¼‰â­

- **æ€§èƒ½**: mAP@0.5=63.59%, ave. mAP=42.90%
- **é…ç½®**: `configs/adatad/anet/e2e_anet_videomaev2_g_192x4_224_adapter_internvideo2.py`
- **æƒé‡**: [Google Drive](https://drive.google.com/file/d/1DQquCFhNNRcK8dAsOT81dsuM4UGZ6HiJ/view?usp=sharing)
- **è¾“å…¥**: 768 frames, 224x224
- **éœ€è¦**: InternVideo2åˆ†ç±»å™¨

#### 2. VideoMAEv2-g + InternVideoï¼ˆæ¬¡ä¼˜ï¼‰

- **æ€§èƒ½**: mAP@0.5=61.74%, ave. mAP=41.85%
- **é…ç½®**: `configs/adatad/anet/e2e_anet_videomaev2_g_192x4_224_adapter_internvideo.py`
- **æƒé‡**: æŸ¥çœ‹logæ–‡ä»¶ä¸­çš„checkpointä¿¡æ¯
- **è¾“å…¥**: 768 frames, 224x224

#### 3. VideoMAE-Lï¼ˆæ— éœ€å¤–éƒ¨åˆ†ç±»å™¨ï¼Œæ¨èç”¨äºéƒ¨ç½²ï¼‰â­â­

- **æ€§èƒ½**: mAP@0.5=59.00%, ave. mAP=39.15%
- **é…ç½®**: `configs/adatad/anet/e2e_anet_videomae_l_192x4_224_adapter_cls.py`
- **æƒé‡**: [Google Drive](https://drive.google.com/file/d/1VYAvDrc7O7W4hDmUjjE6y32WmVNQ4ZR_/view?usp=sharing)
- **è¾“å…¥**: 768 frames, 224x224
- **ä¼˜åŠ¿**: **ç›´æ¥è®­ç»ƒ200ç±»åˆ†ç±»å¤´ï¼Œæ— éœ€å¤–éƒ¨åˆ†ç±»å™¨ï¼Œæœ€é€‚åˆéƒ¨ç½²**

#### 4. VideoMAE-Sï¼ˆè½»é‡çº§ï¼Œé€‚åˆèµ„æºå—é™ï¼‰

- **æ€§èƒ½**: mAP@0.5=56.23%, ave. mAP=37.81%
- **é…ç½®**: `configs/adatad/anet/e2e_anet_videomae_s_192x4_160_adapter.py`
- **æƒé‡**: [Google Drive](https://drive.google.com/file/d/1gncN-xjArNtgVoBKCwCJCH4ISA3yVqIU/view?usp=sharing)
- **è¾“å…¥**: 768 frames, 160x160
- **éœ€è¦**: CUHKåˆ†ç±»å™¨

#### 5. å…¶ä»–æ¨¡å‹

| Backbone | mAP@0.5 | Config | Download |
|----------|---------|--------|----------|
| VideoMAE-B | 56.72% | `e2e_anet_videomae_b_192x4_160_adapter.py` | [Link](https://drive.google.com/file/d/1tePHMitdwUrWax1nYlbucaqI5LbvZhZo/view?usp=sharing) |
| VideoMAE-L | 57.73% | `e2e_anet_videomae_l_192x4_160_adapter.py` | [Link](https://drive.google.com/file/d/1GxwNLc1rRp6x5ug1zd1r_1DmYCZD_tw5/view?usp=sharing) |
| VideoMAE-H | 57.77% | `e2e_anet_videomae_h_192x4_160_adapter.py` | [Link](https://drive.google.com/file/d/1Hqpdq7Qclf0-1oF25tWwZLI8Ranp-uBv/view?usp=sharing) |
| VideoMAEv2-g | 58.42% | `e2e_anet_videomaev2_g_192x4_160_adapter.py` | [Link](https://drive.google.com/file/d/1lfWyWrt1gJOm7YfwCdXi7HiNomHPGvna/view?usp=sharing) |

---

## ğŸš€ å¿«é€Ÿéƒ¨ç½²æ­¥éª¤

### æ­¥éª¤1: ä¸‹è½½é¢„è®­ç»ƒæƒé‡

#### æ¨èï¼šVideoMAE-Lï¼ˆæ— éœ€å¤–éƒ¨åˆ†ç±»å™¨ï¼‰

```bash
# åˆ›å»ºæƒé‡ç›®å½•
mkdir -p /root/OpenTAD/pretrained/adatad

# ä¸‹è½½æƒé‡ï¼ˆä½¿ç”¨gdownæˆ–wgetï¼‰
# æ–¹æ³•1: ä½¿ç”¨gdownï¼ˆéœ€è¦å®‰è£…: pip install gdownï¼‰
gdown https://drive.google.com/uc?id=1VYAvDrc7O7W4hDmUjjE6y32WmVNQ4ZR_ \
    -O /root/OpenTAD/pretrained/adatad/adatad_anet_videomae_l_224_cls.pth

# æ–¹æ³•2: æ‰‹åŠ¨ä¸‹è½½
# 1. åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: https://drive.google.com/file/d/1VYAvDrc7O7W4hDmUjjE6y32WmVNQ4ZR_/view?usp=sharing
# 2. ä¸‹è½½åä¸Šä¼ åˆ°æœåŠ¡å™¨
# scp adatad_anet_videomae_l_224_cls.pth root@<server>:/root/OpenTAD/pretrained/adatad/
```

#### æˆ–é€‰æ‹©å…¶ä»–æ¨¡å‹

```bash
# VideoMAE-S (è½»é‡çº§)
gdown https://drive.google.com/uc?id=1gncN-xjArNtgVoBKCwCJCH4ISA3yVqIU \
    -O /root/OpenTAD/pretrained/adatad/adatad_anet_videomae_s_160.pth

# VideoMAE-L (æ ‡å‡†ç‰ˆï¼Œéœ€è¦åˆ†ç±»å™¨)
gdown https://drive.google.com/uc?id=1GxwNLc1rRp6x5ug1zd1r_1DmYCZD_tw5 \
    -O /root/OpenTAD/pretrained/adatad/adatad_anet_videomae_l_160.pth
```

### æ­¥éª¤2: å‡†å¤‡é…ç½®æ–‡ä»¶

é…ç½®æ–‡ä»¶å·²å­˜åœ¨ï¼š
- **æ¨èï¼ˆæ— éœ€åˆ†ç±»å™¨ï¼‰**: `configs/adatad/anet/e2e_anet_videomae_l_192x4_224_adapter_cls.py`
- **æ ‡å‡†ç‰ˆ**: `configs/adatad/anet/e2e_anet_videomae_s_192x4_160_adapter.py`

### æ­¥éª¤3: å‡†å¤‡æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰

å¦‚æœä½¿ç”¨æ ‡å‡†ç‰ˆï¼ˆéœ€è¦CUHKåˆ†ç±»å™¨ï¼‰ï¼š
```bash
# ä¸‹è½½åˆ†ç±»å™¨æ–‡ä»¶
mkdir -p data/activitynet-1.3/classifiers
# åˆ†ç±»å™¨æ–‡ä»¶è·¯å¾„åœ¨é…ç½®ä¸­æŒ‡å®š: data/activitynet-1.3/classifiers/cuhk_val_simp_7.json
```

### æ­¥éª¤4: è¿è¡Œæ¨ç†

#### ä½¿ç”¨OpenTADæµ‹è¯•è„šæœ¬

```bash
cd /root/OpenTAD

# å•GPUæ¨ç†ï¼ˆæ¨èVideoMAE-Lï¼Œæ— éœ€åˆ†ç±»å™¨ï¼‰
CUDA_VISIBLE_DEVICES=0 torchrun \
    --nnodes=1 \
    --nproc_per_node=1 \
    --rdzv_backend=c10d \
    --rdzv_endpoint=localhost:0 \
    tools/test.py \
    configs/adatad/anet/e2e_anet_videomae_l_192x4_224_adapter_cls.py \
    --checkpoint /root/OpenTAD/pretrained/adatad/adatad_anet_videomae_l_224_cls.pth
```

---

## ğŸ“ åˆ›å»ºæ¨ç†æœåŠ¡è„šæœ¬

åˆ›å»º `video_analysis_service.py`:

```python
#!/usr/bin/env python3
"""
AdaTAD ActivityNet è§†é¢‘åˆ†ææœåŠ¡
ä½¿ç”¨å®˜æ–¹é¢„è®­ç»ƒæƒé‡è¿›è¡Œæ¨ç†
"""

import os
import sys
sys.path.insert(0, "/root/OpenTAD")

import torch
import json
import argparse
from pathlib import Path
from mmengine.config import Config
from opentad.models import build_detector
from opentad.datasets import build_dataset, build_dataloader
from opentad.cores import eval_one_epoch

def main():
    parser = argparse.ArgumentParser(description="AdaTAD Video Analysis Service")

    # æ¨èé…ç½®ï¼ˆæ— éœ€åˆ†ç±»å™¨ï¼‰
    parser.add_argument("--config", type=str,
                       default="configs/adatad/anet/e2e_anet_videomae_l_192x4_224_adapter_cls.py",
                       help="Config file path")
    parser.add_argument("--checkpoint", type=str,
                       default="/root/OpenTAD/pretrained/adatad/adatad_anet_videomae_l_224_cls.pth",
                       help="Checkpoint path")
    parser.add_argument("--video-dir", type=str, required=True,
                       help="Directory containing videos to analyze")
    parser.add_argument("--output", type=str, default="results.json",
                       help="Output JSON path")
    parser.add_argument("--device", type=str, default="cuda:0",
                       help="Device (cuda:0 or cpu)")

    args = parser.parse_args()

    print(f"Loading config from: {args.config}")
    cfg = Config.fromfile(args.config)

    # ä¿®æ”¹æ•°æ®è·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if hasattr(cfg.dataset, 'test'):
        cfg.dataset.test.data_path = args.video_dir

    print(f"Building model...")
    model = build_detector(cfg.model)

    print(f"Loading checkpoint from: {args.checkpoint}")
    checkpoint = torch.load(args.checkpoint, map_location=args.device)
    if "state_dict" in checkpoint:
        model.load_state_dict(checkpoint["state_dict"], strict=False)
        print(f"âœ… Loaded checkpoint from epoch {checkpoint.get('epoch', 'unknown')}")
    else:
        model.load_state_dict(checkpoint, strict=False)
        print("âœ… Loaded checkpoint")

    model.eval()
    model.to(args.device)
    print("âœ… Model ready for inference!")

    # æ„å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    print("Building dataset...")
    test_dataset = build_dataset(cfg.dataset.test)
    test_loader = build_dataloader(
        test_dataset,
        rank=0,
        world_size=1,
        shuffle=False,
        drop_last=False,
        **cfg.solver.test,
    )

    # æ¨ç†
    print("Starting inference...")
    results = []
    with torch.no_grad():
        for batch_idx, data in enumerate(test_loader):
            # å°†æ•°æ®ç§»åˆ°GPU
            if isinstance(data, dict):
                for key in data:
                    if isinstance(data[key], torch.Tensor):
                        data[key] = data[key].to(args.device)

            # æ¨ç†
            output = model(**data, return_loss=False,
                          infer_cfg=cfg.inference,
                          post_cfg=cfg.post_processing)

            results.append(output)
            print(f"Processed batch {batch_idx + 1}")

    # ä¿å­˜ç»“æœ
    with open(args.output, "w") as f:
        json.dump(results, f, indent=2, default=str)

    print(f"âœ… Inference completed! Results saved to {args.output}")

if __name__ == "__main__":
    main()
```

---

## ğŸ”§ ä½¿ç”¨gdownä¸‹è½½Google Driveæ–‡ä»¶

### å®‰è£…gdown

```bash
pip install gdown
```

### ä¸‹è½½æƒé‡

```bash
# VideoMAE-L (æ¨èï¼Œæ— éœ€åˆ†ç±»å™¨)
gdown https://drive.google.com/uc?id=1VYAvDrc7O7W4hDmUjjE6y32WmVNQ4ZR_ \
    -O /root/OpenTAD/pretrained/adatad/adatad_anet_videomae_l_224_cls.pth

# VideoMAE-S (è½»é‡çº§)
gdown https://drive.google.com/uc?id=1gncN-xjArNtgVoBKCwCJCH4ISA3yVqIU \
    -O /root/OpenTAD/pretrained/adatad/adatad_anet_videomae_s_160.pth
```

---

## ğŸ“Š æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | mAP@0.5 | ave. mAP | è¾“å…¥å°ºå¯¸ | éœ€è¦åˆ†ç±»å™¨ | æ¨èåº¦ |
|------|---------|----------|----------|-----------|--------|
| **VideoMAE-L (cls)** | 59.00% | 39.15% | 224x224 | âŒ ä¸éœ€è¦ | â­â­â­â­â­ |
| VideoMAE-S | 56.23% | 37.81% | 160x160 | âœ… CUHK | â­â­â­ |
| VideoMAE-L | 57.73% | 39.21% | 160x160 | âœ… CUHK | â­â­â­â­ |
| VideoMAEv2-g | 58.42% | 39.77% | 160x160 | âœ… CUHK | â­â­â­â­ |
| VideoMAEv2-g+InternVideo2 | 63.59% | 42.90% | 224x224 | âœ… InternVideo2 | â­â­â­â­â­ |

---

## ğŸ¯ æ¨èéƒ¨ç½²æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: VideoMAE-L (cls) - æœ€ç®€å•ï¼ˆæ¨èï¼‰â­

**ä¼˜ç‚¹**:
- âœ… æ— éœ€å¤–éƒ¨åˆ†ç±»å™¨
- âœ… ç›´æ¥è¾“å‡º200ç±»åŠ¨ä½œ
- âœ… éƒ¨ç½²æœ€ç®€å•
- âœ… æ€§èƒ½è‰¯å¥½ï¼ˆmAP@0.5=59.00%ï¼‰

**é…ç½®**:
- Config: `configs/adatad/anet/e2e_anet_videomae_l_192x4_224_adapter_cls.py`
- Checkpoint: `adatad_anet_videomae_l_224_cls.pth`
- ä¸‹è½½: https://drive.google.com/file/d/1VYAvDrc7O7W4hDmUjjE6y32WmVNQ4ZR_/view?usp=sharing

### æ–¹æ¡ˆ2: VideoMAE-S - è½»é‡çº§

**ä¼˜ç‚¹**:
- âœ… æ¨¡å‹è¾ƒå°ï¼Œæ¨ç†é€Ÿåº¦å¿«
- âœ… æ˜¾å­˜å ç”¨å°‘

**ç¼ºç‚¹**:
- âŒ éœ€è¦CUHKåˆ†ç±»å™¨
- âš ï¸ æ€§èƒ½ç•¥ä½

---

## ğŸ“‹ å®Œæ•´éƒ¨ç½²ç¤ºä¾‹

```bash
# 1. ä¸‹è½½æƒé‡
mkdir -p /root/OpenTAD/pretrained/adatad
cd /root/OpenTAD/pretrained/adatad

# ä½¿ç”¨gdownä¸‹è½½ï¼ˆæ¨èï¼‰
pip install gdown
gdown https://drive.google.com/uc?id=1VYAvDrc7O7W4hDmUjjE6y32WmVNQ4ZR_ \
    -O adatad_anet_videomae_l_224_cls.pth

# 2. å‡†å¤‡è§†é¢‘ç›®å½•
mkdir -p /data/videos/input
# å°†è§†é¢‘æ”¾å…¥è¯¥ç›®å½•

# 3. è¿è¡Œæ¨ç†
cd /root/OpenTAD
CUDA_VISIBLE_DEVICES=0 torchrun \
    --nnodes=1 \
    --nproc_per_node=1 \
    --rdzv_backend=c10d \
    --rdzv_endpoint=localhost:0 \
    tools/test.py \
    configs/adatad/anet/e2e_anet_videomae_l_192x4_224_adapter_cls.py \
    --checkpoint /root/OpenTAD/pretrained/adatad/adatad_anet_videomae_l_224_cls.pth \
    --cfg-options dataset.test.data_path=/data/videos/input
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **åˆ†ç±»å™¨æ–‡ä»¶**:
   - VideoMAE-L (cls)ç‰ˆæœ¬**ä¸éœ€è¦**åˆ†ç±»å™¨
   - å…¶ä»–ç‰ˆæœ¬éœ€è¦CUHKåˆ†ç±»å™¨: `data/activitynet-1.3/classifiers/cuhk_val_simp_7.json`

2. **è§†é¢‘æ ¼å¼**: æ”¯æŒMP4ç­‰å¸¸è§æ ¼å¼

3. **GPUå†…å­˜**:
   - VideoMAE-S: å»ºè®®è‡³å°‘4GB
   - VideoMAE-L: å»ºè®®è‡³å°‘8GB
   - VideoMAEv2-g: å»ºè®®è‡³å°‘16GB

4. **è¾“å…¥è¦æ±‚**:
   - è§†é¢‘ä¼šè‡ªåŠ¨resizeåˆ°é…ç½®çš„å°ºå¯¸
   - æ—¶åºé•¿åº¦: 768 frames

---

## ğŸ“š å‚è€ƒèµ„æº

- **OpenTAD GitHub**: https://github.com/sming256/OpenTAD
- **AdaTAD README**: `configs/adatad/README.md`
- **é…ç½®æ–‡ä»¶**: `configs/adatad/anet/e2e_anet_videomae_l_192x4_224_adapter_cls.py`
- **ActivityNetå®˜ç½‘**: http://activity-net.org/

---

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **ä¸‹è½½é¢„è®­ç»ƒæƒé‡**ï¼ˆæ¨èVideoMAE-L clsç‰ˆæœ¬ï¼‰
2. **å‡†å¤‡æµ‹è¯•è§†é¢‘**
3. **è¿è¡Œæ¨ç†æµ‹è¯•**
4. **æ ¹æ®éœ€è¦åˆ›å»ºAPIæœåŠ¡**

**æ¨èä½¿ç”¨VideoMAE-L (cls)ç‰ˆæœ¬ï¼Œå› ä¸ºå®ƒæ— éœ€å¤–éƒ¨åˆ†ç±»å™¨ï¼Œéƒ¨ç½²æœ€ç®€å•ï¼**
