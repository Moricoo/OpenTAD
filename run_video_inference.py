# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„è§†é¢‘æ¨ç†è„šæœ¬ - ä½¿ç”¨ OpenTAD æ¡†æ¶å¯¹å•ä¸ª MP4 è§†é¢‘è¿›è¡ŒåŠ¨ä½œæ£€æµ‹
"""
import os
import sys
sys.path.insert(0, "/root/OpenTAD")
os.chdir("/root/OpenTAD")

import torch
import json
import numpy as np
from mmengine.config import Config
from opentad.models import build_detector
from opentad.datasets import build_dataset, build_dataloader

def main():
    # è·¯å¾„é…ç½®
    config_path = "model_package_thumos_adapter_baseline/config/e2e_thumos_videomae_s_768x1_160_adapter.py"
    checkpoint_path = "model_package_thumos_adapter_baseline/checkpoint/latest.pth"
    video_path = "03-è¥¿ç­ç‰™é€›è¡—æ—¥å¸¸-2-28.mp4"
    ann_file = "inference_annotation.json"
    class_map = "inference_category_idx.txt"
    output_path = "inference_results.json"
    
    print("=" * 70)
    print("æ—¶åºåŠ¨ä½œæ£€æµ‹æ¨ç† - å•ä¸ªè§†é¢‘")
    print("=" * 70)
    
    # 1. åŠ è½½é…ç½®
    print("\n[1/5] åŠ è½½é…ç½®æ–‡ä»¶...")
    cfg = Config.fromfile(config_path)
    
    # ä¿®æ”¹æ•°æ®é›†é…ç½®ä»¥ä½¿ç”¨æˆ‘ä»¬çš„è§†é¢‘
    cfg.dataset.test.ann_file = ann_file
    cfg.dataset.test.class_map = class_map
    cfg.dataset.test.data_path = "."  # å½“å‰ç›®å½•
    cfg.dataset.test.subset_name = "test"
    
    print(f"  âœ… é…ç½®åŠ è½½æˆåŠŸ")
    print(f"  ğŸ“‹ Annotation æ–‡ä»¶: {ann_file}")
    print(f"  ğŸ“‹ ç±»åˆ«æ˜ å°„æ–‡ä»¶: {class_map}")
    print(f"  ğŸ“¹ è§†é¢‘è·¯å¾„: {video_path}")
    
    # 2. æ„å»ºæ¨¡å‹
    print("\n[2/5] æ„å»ºæ¨¡å‹...")
    model = build_detector(cfg.model)
    print("  âœ… æ¨¡å‹æ„å»ºæˆåŠŸ")
    
    # 3. åŠ è½½æƒé‡
    print("\n[3/5] åŠ è½½æ¨¡å‹æƒé‡...")
    checkpoint = torch.load(checkpoint_path, map_location="cuda:0")
    if "state_dict" in checkpoint:
        model.load_state_dict(checkpoint["state_dict"], strict=False)
        print("  âœ… ä» state_dict åŠ è½½æƒé‡")
    else:
        model.load_state_dict(checkpoint, strict=False)
        print("  âœ… ç›´æ¥åŠ è½½æƒé‡")
    
    model.eval()
    model.cuda()
    print("  âœ… æ¨¡å‹å·²åŠ è½½åˆ° GPU")
    
    # 4. æ„å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    print("\n[4/5] æ„å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨...")
    dataset = build_dataset(cfg.dataset.test)
    print(f"  âœ… æ•°æ®é›†æ„å»ºæˆåŠŸï¼Œå…± {len(dataset)} ä¸ªæ ·æœ¬")
    
    dataloader = build_dataloader(
        dataset, 
        batch_size=cfg.solver.test.batch_size,
        rank=0,
        world_size=1,
        num_workers=cfg.solver.test.num_workers
    )
    print(f"  âœ… æ•°æ®åŠ è½½å™¨æ„å»ºæˆåŠŸ")
    
    # 5. æ‰§è¡Œæ¨ç†
    print("\n[5/5] å¼€å§‹æ¨ç†...")
    all_results = []
    
    with torch.no_grad():
        for batch_idx, data in enumerate(dataloader):
            # å°†æ•°æ®ç§»åˆ° GPU
            if isinstance(data, dict):
                for key in data:
                    if isinstance(data[key], torch.Tensor):
                        data[key] = data[key].cuda()
            
            # æ¨ç† - ä½¿ç”¨æµ‹è¯•æ¨¡å¼
            try:
                # ç§»é™¤è®­ç»ƒç›¸å…³çš„é”®
                test_data = {k: v for k, v in data.items() if k not in ['gt_segments', 'gt_labels']}
                output = model.forward_test(**test_data)
                
                # å¤„ç†è¾“å‡º
                if isinstance(output, (list, tuple)):
                    output = output[0]
                
                # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
                def convert_to_serializable(obj):
                    if isinstance(obj, torch.Tensor):
                        return obj.cpu().numpy().tolist()
                    elif isinstance(obj, np.ndarray):
                        return obj.tolist()
                    elif isinstance(obj, dict):
                        return {k: convert_to_serializable(v) for k, v in obj.items()}
                    elif isinstance(obj, (list, tuple)):
                        return [convert_to_serializable(item) for item in obj]
                    else:
                        return obj
                
                result = convert_to_serializable(output)
                all_results.append(result)
                
                print(f"  âœ… æ‰¹æ¬¡ {batch_idx + 1}/{len(dataloader)} æ¨ç†å®Œæˆ")
                
            except Exception as e:
                print(f"  âš ï¸  æ‰¹æ¬¡ {batch_idx + 1} æ¨ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                continue
    
    # ä¿å­˜ç»“æœ
    print(f"\nğŸ’¾ ä¿å­˜ç»“æœåˆ°: {output_path}")
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump({
            "video": video_path,
            "results": all_results,
            "num_batches": len(all_results)
        }, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 70)
    print("âœ… æ¨ç†å®Œæˆï¼")
    print(f"ğŸ“Š å¤„ç†äº† {len(all_results)} ä¸ªæ‰¹æ¬¡")
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    print("=" * 70)

if __name__ == "__main__":
    main()

